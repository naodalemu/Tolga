<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <link rel="stylesheet" href="../CSS/style.css">
    <title>Machine Learning Competitions</title>
</head>

<body>

    <section class="main-container">

        <div class="aligner">

            <h1 class="chapter-title">Machine Learning Competitions</h1>
            <p class="title-description adjust-title-desc">Enter the world of machine learning competitions to keep improving and see your progress.</p>

            <h2 class="sub-header">Introduction</h2>
            <p class="basic-text">Decision trees leave you with a difficult decision. A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.</p>
            <p class="basic-text">Even today's most sophisticated modeling techniques face this tension between underfitting and overfitting. But, many models have clever ideas that can lead to better performance. We'll look at the <b>random forest</b> as an example.</p>
            <p class="basic-text">The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters.</p>
            
            <h2 class="sub-header">Example</h2>
            <p class="basic-text">You've already seen the code to load the data a few times. At the end of data-loading, we have the following variables:</p>
            <ul class="lists">
                <li class="list-content basic-text">train_X</li>
                <li class="list-content basic-text">val_X</li>
                <li class="list-content basic-text">train_y</li>
                <li class="list-content basic-text">val_y</li>
            </ul>

            <div class="show-and-hide-question">
                <p class="basic-text show-toggle">Show hidden code</p>
                <p class="basic-text hide-toggle hide-question-toggle">Hide code</p>
                <hr class="hideline">
            </div>

            <div class="code-snippet-container adjust-stuff hidden-question">
                <div class="code-snippet">
                    <pre>
                        <code class="language-python">
import pandas as pd

# Load data
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
# Filter rows with missing values
melbourne_data = melbourne_data.dropna(axis=0)
# Choose target and features
y = melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']
X = melbourne_data[melbourne_features]

from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)
                        </code>
                    </pre>
                    <div class="try-it">Try it yourself &RightAngleBracket;&RightAngleBracket;</div>
                </div>
            </div>

            <p class="basic-text below-hidden-text">We build a random forest model similarly to how we built a decision tree in scikit-learn - this time using the <span class="inline-code">RandomForestRegressor</span> class instead of <span class="inline-code">DecisionTreeRegressor</span>.</p>

            <div class="code-snippet-container adjust-stuff">
                <div class="code-snippet">
                    <pre>
                        <code class="language-python">
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

forest_model = RandomForestRegressor(random_state=1)
forest_model.fit(train_X, train_y)
melb_preds = forest_model.predict(val_X)
print(mean_absolute_error(val_y, melb_preds))
                        </code>
                    </pre>
                    <div class="try-it">Try it yourself &RightAngleBracket;&RightAngleBracket;</div>
                </div>

                <p class="output-indicator">Output:</p>

                <div class="code-result">
                    <pre>
                        <code class="output language-python">
191669.7536453626
                        </code>
                    </pre>
                </div>
            </div>

            <h2 class="sub-header">Conclusion</h2>
            <p class="basic-text">There is likely room for further improvement, but this is a big improvement over the best decision tree error of 250,000. There are parameters which allow you to change the performance of the Random Forest much as we changed the maximum depth of the single decision tree. But one of the best features of Random Forest models is that they generally work reasonably even without this tuning.</p>

            <div class="navigation" style="display: flex; justify-content: space-between; font-size: 100px;">
                <div class="previous" style="cursor: pointer;"><a href="Chapterfive.html"
                        style="text-decoration: none;">&leftarrow;</a></div>
                <div class="next" style="cursor: pointer;"><a href="" style="text-decoration: none;">&rightarrow;</a>
                </div>
            </div>

        </div>

    </section>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script src="../Script/script.js"></script>
</body>

</html>